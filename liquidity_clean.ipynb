{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r09HJ7xg1sc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47c8538f-adf3-4406-ccef-67b77e515111"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# Specify the file path\n",
        "csv_file = '/content/drive/MyDrive/0/xnas-itch-20220801.trades.csv'\n",
        "\n",
        "# Open and read the CSV file\n",
        "with open(csv_file, mode='r') as file:\n",
        "    reader = csv.reader(file)\n",
        "\n",
        "    # Get the headers (field names)\n",
        "    headers = next(reader)\n",
        "    print(\"Fields in the CSV file:\")\n",
        "    for field in headers:\n",
        "        print(field)\n",
        "\n",
        " # Print the first few rows for debugging\n",
        "    print(f\"Preview of {filename}:\")\n",
        "    for i, row in enumerate(reader):\n",
        "        if i < 5:  # Print only the first 5 rows\n",
        "            print(row)\n",
        "        filtered_row = {field: row[field] for field in fields_to_keep if field in row}\n",
        "        writer.writerow(filtered_row)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 592
        },
        "id": "f9e0gZsu882h",
        "outputId": "f1f6721b-7050-40ba-d45c-d5ed1be3ebf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fields in the CSV file:\n",
            "ts_recv\n",
            "ts_event\n",
            "rtype\n",
            "publisher_id\n",
            "instrument_id\n",
            "action\n",
            "side\n",
            "depth\n",
            "price\n",
            "size\n",
            "flags\n",
            "ts_in_delta\n",
            "sequence\n",
            "symbol\n",
            "Preview of xnas-itch-20220810.trades.csv:\n",
            "['2022-08-01T08:00:13.027169890Z', '2022-08-01T08:00:13.027158303Z', '0', '2', '4837', 'T', 'B', '0', '116.430000000', '48', '130', '11587', '343931', 'GOOGL']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "I/O operation on closed file.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5c23dadecba6>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mfiltered_row\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfield\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfields_to_keep\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mfield\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.10/csv.py\u001b[0m in \u001b[0;36mwriterow\u001b[0;34m(self, rowdict)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrowdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dict_to_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrowdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwriterows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrowdicts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: I/O operation on closed file."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import os\n",
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "# Specify the folder containing the CSV files\n",
        "input_folder = \"/content/drive/MyDrive/0\"  # Replace with your actual path\n",
        "output_file = \"combined_output.csv\"\n",
        "\n",
        "# Validate input folder\n",
        "if not os.path.exists(input_folder):\n",
        "    print(f\"Error: Input folder '{input_folder}' does not exist.\")\n",
        "    exit(1)\n",
        "\n",
        "# List of fields to keep\n",
        "fields_to_keep = [\"size\", \"price\", \"ts_event\", \"side\", \"symbol\"]\n",
        "\n",
        "# Initialize a dictionary to aggregate data\n",
        "aggregated_data = defaultdict(lambda: {\"size\": 0, \"price_sum\": 0, \"price_count\": 0, \"symbol\": None})\n",
        "\n",
        "# Process each CSV file in the folder\n",
        "for filename in os.listdir(input_folder):\n",
        "    file_path = os.path.join(input_folder, filename)\n",
        "\n",
        "    # Skip non-CSV files\n",
        "    if not filename.endswith(\".csv\") or not os.path.isfile(file_path):\n",
        "        continue\n",
        "\n",
        "    with open(file_path, mode='r') as input_csv:\n",
        "        reader = csv.DictReader(input_csv)\n",
        "\n",
        "        # Aggregate rows by ts_event and side\n",
        "        for row in reader:\n",
        "            if all(field in row for field in fields_to_keep):\n",
        "                ts_event = row[\"ts_event\"].split('T')[0] if 'T' in row[\"ts_event\"] else row[\"ts_event\"]\n",
        "                side = row[\"side\"]\n",
        "                key = (ts_event, side)\n",
        "\n",
        "                aggregated_data[key][\"size\"] += float(row[\"size\"])\n",
        "                aggregated_data[key][\"price_sum\"] += float(row[\"price\"])\n",
        "                aggregated_data[key][\"price_count\"] += 1\n",
        "                aggregated_data[key][\"symbol\"] = row[\"symbol\"]  # Assume the symbol is the same for each key\n",
        "\n",
        "# Write the aggregated data to the output file\n",
        "with open(output_file, mode='w', newline='') as output_csv:\n",
        "    writer = csv.DictWriter(output_csv, fieldnames=[\"ts_event\", \"side\", \"size\", \"price\", \"symbol\"])\n",
        "    writer.writeheader()\n",
        "\n",
        "    for (ts_event, side), data in aggregated_data.items():\n",
        "        writer.writerow({\n",
        "            \"ts_event\": ts_event,\n",
        "            \"side\": side,\n",
        "            \"size\": data[\"size\"],\n",
        "            \"price\": data[\"price_sum\"] / data[\"price_count\"],  # Calculate mean price\n",
        "            \"symbol\": data[\"symbol\"]\n",
        "        })\n",
        "\n",
        "print(f\"Aggregated CSV file saved as: {output_file}\")\n"
      ],
      "metadata": {
        "id": "S7WRKPIb-uNv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3d112ca-011d-4d82-e8be-971442c7d0fe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aggregated CSV file saved as: combined_output.csv\n"
          ]
        }
      ]
    }
  ]
}